"""
–ú–æ–¥—É–ª—å –ø–∞—Ä—Å–∏–Ω–≥–∞ RSS-–ª–µ–Ω—Ç.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π.
"""

import asyncio
import logging
import re
from typing import List, Dict, Any
from datetime import datetime

import feedparser

logger = logging.getLogger("NewsBot.RSS")


class RSSParser:
    """
    –ü–∞—Ä—Å–µ—Ä RSS-–ª–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç asyncio –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏.
    """

    def __init__(self, feeds: tuple):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞.
        
        Args:
            feeds: –∫–æ—Ä—Ç–µ–∂ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ RSS-–ª–µ–Ω—Ç–∞—Ö
        """
        self.feeds = feeds
        logger.info(f"RSS –ø–∞—Ä—Å–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å {len(feeds)} –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏")

    async def fetch_feed(self, feed_info: Dict[str, str]) -> List[Dict[str, Any]]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –æ–¥–Ω–æ–π RSS-–ª–µ–Ω—Ç—ã.
        
        Args:
            feed_info: —Å–ª–æ–≤–∞—Ä—å —Å name, url, icon
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π
        """
        name = feed_info["name"]
        url = feed_info["url"]
        icon = feed_info.get("icon", "üì∞")
        
        try:
            logger.debug(f"–ó–∞–≥—Ä—É–∑–∫–∞ RSS: {name}")
            
            # feedparser —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π, –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ thread
            loop = asyncio.get_running_loop()
            feed = await loop.run_in_executor(None, feedparser.parse, url)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
            if feed.bozo:
                logger.warning(f"RSS –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ [{name}]: {feed.bozo_exception}")
            
            articles = []
            for entry in feed.entries[:10]:  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10
                article = {
                    "title": self._clean_text(entry.get("title", "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞")),
                    "link": entry.get("link", ""),
                    "summary": self._clean_html(entry.get("summary", "")),
                    "published": self._parse_date(entry.get("published")),
                    "author": entry.get("author", ""),
                    "source": name,
                    "source_icon": icon,
                }
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å
                if hasattr(entry, "content") and entry.content:
                    article["content"] = self._clean_html(
                        entry.content[0].get("value", "")
                    )
                else:
                    article["content"] = article["summary"]
                
                articles.append(article)
            
            logger.info(f"‚úì {name}: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π")
            return articles
            
        except Exception as e:
            logger.error(f"‚úó {name}: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ - {e}")
            return []

    async def fetch_all(self) -> List[Dict[str, Any]]:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö RSS-–ª–µ–Ω—Ç.
        
        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ –¥–∞—Ç–µ
        """
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ {len(self.feeds)} RSS-–ª–µ–Ω—Ç...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = [self.fetch_feed(feed) for feed in self.feeds]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_articles = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ: {result}")
            elif isinstance(result, list):
                all_articles.extend(result)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
        all_articles.sort(
            key=lambda x: x.get("published") or datetime.min,
            reverse=True
        )
        
        logger.info(f"–í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_articles)} —Å—Ç–∞—Ç–µ–π –∏–∑ {len(self.feeds)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
        return all_articles

    @staticmethod
    def _clean_html(text: str) -> str:
        """–£–¥–∞–ª–µ–Ω–∏–µ HTML-—Ç–µ–≥–æ–≤ –∏ –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞."""
        if not text:
            return ""
        
        # –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
        clean = re.sub(r"<[^>]+>", " ", text)
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
        clean = re.sub(r"\s+", " ", clean).strip()
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º HTML-—Å—É—â–Ω–æ—Å—Ç–∏
        entities = {
            "&amp;": "&",
            "&lt;": "<",
            "&gt;": ">",
            "&quot;": '"',
            "&#39;": "'",
            "&nbsp;": " ",
            "&mdash;": "‚Äî",
            "&ndash;": "‚Äì",
        }
        for entity, char in entities.items():
            clean = clean.replace(entity, char)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        return clean[:2000]

    @staticmethod
    def _clean_text(text: str) -> str:
        """–ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞."""
        if not text:
            return ""
        return re.sub(r"\s+", " ", text).strip()

    @staticmethod
    def _parse_date(date_str: str) -> datetime:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤."""
        if not date_str:
            return datetime.now()
        
        # feedparser –æ–±—ã—á–Ω–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç parsed time tuple
        try:
            from time import mktime
            import feedparser
            parsed = feedparser._parse_date(date_str)
            if parsed:
                return datetime.fromtimestamp(mktime(parsed))
        except Exception:
            pass
        
        return datetime.now()
